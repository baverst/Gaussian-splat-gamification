\documentclass[12pt]{article}

\usepackage{listings}
\renewcommand{\lstlistingname}{Code}
\usepackage{xcolor}
\lstdefinestyle{sharpc}{language=[Sharp]C, frame=lr, rulecolor=\color{blue!80!black}}
\usepackage{graphicx}
\usepackage[style=authoryear]{biblatex}
\usepackage{setspace}
\addbibresource{references.bib}
\onehalfspacing

\begin{document}

\begin{titlepage}
	\centering
	
	%opening
	\title{Multi-Splat Representations \\ {\large Segmentation and Object Manipulation in Gaussian Splatting}}
	
	\author{Bavo Verstraeten}
	
	
	
	\maketitle
\end{titlepage}
	
\begin{abstract}
Gaussian splatting is a novel technique for real-time rendering of complex scenes, but integrating this approach seamlessly into game engines remains a challenge. This thesis focuses on improving the usability and accuracy of Gaussian splats within the Unity engine, building upon an existing open-source Unity extension.
\\\\
The work is divided into two main parts. The first addresses a core rendering limitation of the current Unity extension, which performs Gaussian splat sorting and rendering on a per-GameObject basis. This results in incorrect visual output when multiple splat objects are placed close together. To resolve this, the rendering pipeline was adapted to implement global per-splat sorting. The result is a fully correct and visually consistent rendering of overlapping Gaussian splat GameObjects.
\\\\
The second part tackles the challenge of preparing Gaussian Splats for animation and interaction within Unity. Animating splats effectively requires a segmented, hierarchical structure — typically represented by nested GameObjects. However, manual segmentation of Gaussian Splats is tedious and error-prone. This thesis proposes a semi-automatic segmentation pipeline, combining three existing tools — SAM, SAM2, and SAGS — to allow user-guided segmentation of Gaussian Splat data. The system accepts user-defined points to guide segmentation and automatically produces a hierarchically structured GameObject, enabling easier manipulation and animation workflows within Unity.
\\\\
Together, these contributions form a streamlined pipeline that improves both the visual fidelity and usability of Gaussian Splats in game development contexts, bringing this cutting-edge technique closer to practical deployment in real-time interactive applications.
\end{abstract}

\begin{titlepage}
\centering
\tableofcontents
\end{titlepage}
\section{Background}
\subsection{From Meshes to Gaussian Splatting}
\subsubsection{Triangle Meshes}
In the field of computer graphics, the efficient rendering of complex 3D scenes has consistently posed a significant challenge. Traditional rendering techniques predominantly rely on triangle meshes, where the representation of surfaces is approximated through a network of interconnected triangles. While these methods have proven effective in many applications, they encounter limitations when dealing with highly detailed or non-uniform data. Achieving photorealistic results in such cases necessitates considerable memory and computational resources. Furthermore, these approaches are heavily dependent on manually crafted 3D models, a process that is both time-consuming and requires skilled artist. The generation of models from video or a collection of images offers the potential for a significantly simpler and more scalable solution.
\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Images/TriangleMesh.png}
	\caption{Example of a triangle mesh, the most commonly used method for representing 3D objects in computer graphics. Image is taken from \cite{Mesh}}
	\label{fig:trianglemesh}
\end{figure}
\newpage
\subsubsection{Neural Radiance Fields}
One popular approach to addressing these challenges is Neural Radiance Fields (NeRF) \parencite{Nerf}, introduced in 2020. This method employs a neural network to learn a mapping from 3D position and viewing direction to an RGB color and density. The network is trained on a video or a collection of images, allowing it to reconstruct a scene by learning the underlying volumetric representation. During rendering, a ray is cast through each pixel of the screen, and multiple points along the ray are sampled. The neural network takes the position of each point and the viewing direction of the ray as input, producing color and density values. These outputs are then aggregated to compute the final color of the pixel, enabling the generation of photorealistic scenes without the need for manually crafted 3D models. However, due to the necessity of querying the neural network multiple times per pixel, this approach is computationally expensive and not suitable for real-time rendering.
\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Images/Nerf.png}
	\caption{Rendering a scene using Neural Radiance Fields. Image is taken from \cite{Nerf}}
	\label{fig:nerf}
\end{figure}
\subsubsection{Gaussian Splatting}
In 2023, a method was introduced that retained the advantages of Neural Radiance Fields, while achieving real-time processing: Gaussian Splatting \parencite{OriginalSplatting}. Like Neural Radiance Fields, Gaussian Splatting uses a video or a collection of images as input to automatically generate the 3D scene data. However, rather than relying on a neural network to represent the data, the scene is represented as a collection of numerous small 3D Gaussians.
\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Images/GaussianForm.png}
	\caption{Illustration of Gaussian functions in different dimensions, shown left to right: 1D Gaussian \parencite{1DGaussian}, 2D Gaussian \parencite{2DGaussian}, and 3D Gaussian \parencite{3DGaussian}}
	\label{fig:Form}
\end{figure}
\newpage  \noindent
Each Gaussian is defined by several attributes that determine its appearance and behavior during rendering:
\begin{itemize}
	\item 3D coordinates
	\item Opacity (transparency)
	\item Anisotropic covariance: The degree to which the Gaussian is 'stretched' along each of the three axes independently
	\item Spherical Harmonics: The color of the Gaussian, which varies depending on the viewing angle
\end{itemize}
The key advantage of this approach is the way the scene is rendered. Instead of relying on rays or neural networks, which are computationally expensive, Gaussian Splatting leverages a rasterization technique. In this process, the 3D Gaussians are projected directly onto the 2D screen space, where they are rendered as small, disk-like splats (when this paper refers to 'splats', it means one such disk-like object). These splats are then blended together based on their spatial overlap, opacity, and color attributes.\\
Furthermore, state-of-the-art triangle mesh rendering also relies on rasterization, meaning that this approach already benefits from many well-established optimizations in graphics hardware. These optimizations, including efficient handling of spatial data and parallel processing, are directly applicable to Gaussian Splatting. By utilizing the same rendering pipeline, Gaussian Splatting can leverage these optimizations for further efficiency gains, making it an ideal choice for real-time rendering applications.
\subsection{Unity Extension}
\subsubsection{Introduction}
When it comes to the gamification of this technique, multiple engines come to mind, such as Unity, Godot, and Unreal Engine. Among these, Unity was chosen due to prior experience with the engine. Additionally, a widely referenced GitHub project \parencite{Aras} implementing Gaussian Splatting in Unity provides a strong foundation for further research. This project stands out not only for its recognition within the community \parencite{ArasRecc1} \parencite{ArasRecc2}, but also for its developer, Aras Pranckevičius, a former Unity engineer with 15 years of experience working on the engine. His expertise suggests that the rendering pipeline adaptations are both well-optimized and efficiently integrated, making this implementation a suitable choice for exploration and development.
\\\\
Before examining the objectives of this thesis and the adaptations made to the selected implementation, it is essential to first outline the relevant aspects of its rendering pipeline. The discussion will focus solely on components that directly influence the rendering process. Certain aspects, such as the compression and storage of Gaussian Splats in files, among others, fall outside the scope of this explanation and will not be covered.
\subsubsection{Adding a Gaussian Splat to the Scene}
The selected project does not implement the training of Gaussian Splats but instead relies on pretrained models obtained from an external source. These models are not used in their original format; rather, the project includes a Unity Editor extension that converts them into a more efficient and compressed representation. As previously mentioned, the specifics of this compression process have minimal impact on rendering and will therefore not be discussed in detail. Once the compressed asset is generated, the user must manually create a new empty GameObject and attach the \texttt{GaussianSplatRenderer} script to it. This script includes a field labeled Asset, into which the compressed asset must be assigned. Upon doing so, the Gaussian Splat appears in the scene. Like any GameObject in Unity, it can be translated, rotated, and scaled. This process can be repeated to instantiate multiple Gaussian Splats within the same scene.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{Images/SplatCreator.png}
	\caption{The Unity Editor extension included in the project for converting PLY files into the required compressed format}
	\label{fig:creator}
\end{figure}
\subsubsection{Initializing the Rendering Process: The Role of \texttt{OnEnable}}
When no GameObjects with an attached \texttt{GaussianSplatRenderer} script are present, the renderer follows the standard rendering pipeline. However, once such a GameObject is enabled, its \texttt{OnEnable} method is executed, performing several initialization tasks. The method is outlined in the following code fragment:
\lstset{style=sharpc}
\begin{lstlisting}[tabsize=2,caption=\texttt{onEnable} of \texttt{GaussianSplatRenderer}, label=code:rendereronenable,breaklines=true,breakatwhitespace=true,basicstyle=\ttfamily\footnotesize]
public void OnEnable()
{
  // Check if necessary shaders and compute shaders are available

	// Initialize materials (details omitted, see later)
	
	// Initialize the sorter
	
	GaussianSplatRenderSystem.instance.RegisterSplat(this);
	
	// Initialize all the graphics buffers
}
\end{lstlisting}
As demonstrated in the code segment, the \texttt{OnEnable} method calls the \linebreak\texttt{RegisterSplat} function of \texttt{GaussianSplatRenderSystem}, a singleton class. This class plays a pivotal role in managing the multiple \linebreak\texttt{GaussianSplatRenderer} objects within the scene and is responsible for executing the changes that modify the rendering process. The implementation of the \texttt{RegisterSplat} function is as follows:
\begin{lstlisting}[tabsize=2,caption=\texttt{RegisterSplat} of \texttt{GaussianSplatRenderSystem}, label=code:systemregister,breaklines=true,breakatwhitespace=true,basicstyle=\ttfamily\footnotesize]
public void RegisterSplat(GaussianSplatRenderer r)
{
	if (m_Splats.Count == 0)
	{
		if (GraphicsSettings.currentRenderPipeline == null)
		Camera.onPreCull += OnPreCullCamera;
	}
	m_Splats.Add(r, new MaterialPropertyBlock());
}
\end{lstlisting}
The \texttt{GaussianSplatRenderSystem} maintains a dictionary of all enabled \linebreak\texttt{GaussianSplatRenderer} objects. When this function is invoked, and no other \texttt{GaussianSplatRenderer} are registered, the method subscribes to the \texttt{Camera.onPreCull} event, linking it to the \texttt{OnPreCullCamera} method.\\
When a \texttt{GaussianSplatRenderer} is disabled, it clears all associated buffers and materials, removes the object from the internal dictionary, and unsubscribes from the \texttt{onPreCull} event when the last \texttt{GaussianSplatRenderer} is removed, effectively managing resources and maintaining system efficiency.
\subsubsection{The Rendering Pipeline}
Each frame, the Unity engine performs culling before rendering the scene, determining which objects lie within the camera’s view and should be processed for rendering. Since splats may appear outside of the camera’s view, the moment just prior to culling is an optimal point at which to prepare these splats and enqueue their draw procedure in the command buffer for execution during the rendering stage. That moment is when \texttt{onPreCull} calls are made.\\
As previously mentioned, when the first \texttt{GaussianSplatRenderer} is enabled, the \texttt{OnPreCullCamera} function is linked to \texttt{onPreCull}. The implementation of this function is as follows:
\begin{lstlisting}[tabsize=2,caption=\texttt{OnPreCullCamera} of \texttt{GaussianSplatRenderSystem}, label=code:systemprecull,breaklines=true,breakatwhitespace=true,basicstyle=\ttfamily\footnotesize]
void OnPreCullCamera(Camera cam)
{
	if (!GatherSplatsForCamera(cam))
	return;
	
	InitialClearCmdBuffer(cam);
	
	m_CommandBuffer.GetTemporaryRT( GaussianSplatRenderer.Props.GaussianSplatRT, -1, -1, 0, FilterMode.Point, GraphicsFormat.R16G16B16A16_SFloat);
	m_CommandBuffer.SetRenderTarget( GaussianSplatRenderer.Props.GaussianSplatRT, BuiltinRenderTextureType.CurrentActive);
	m_CommandBuffer.ClearRenderTarget(RTClearFlags.Color, new Color(0, 0, 0, 0), 0, 0);
	
	// add sorting, view calc and drawing commands for each splat object
	Material matComposite = SortAndRenderSplats(cam, m_CommandBuffer);
	
	// compose
	m_CommandBuffer.BeginSample(s_ProfCompose);
	m_CommandBuffer.SetRenderTarget( BuiltinRenderTextureType.CameraTarget);
	m_CommandBuffer.DrawProcedural(Matrix4x4.identity, matComposite, 0, MeshTopology.Triangles, 3, 1);
	m_CommandBuffer.EndSample(s_ProfCompose);
	m_CommandBuffer.ReleaseTemporaryRT( GaussianSplatRenderer.Props.GaussianSplatRT);
}
\end{lstlisting}
This function performs 5 key operations:
\begin{itemize}
	\item \texttt{GatherSplatsForCamera}: This function first iterates over all key-value pairs in \texttt{m\textunderscore Splats} and selects those that have a valid compressed asset assigned, storing them in the list \texttt{m\textunderscore ActiveSplats}. Subsequently, this list is sorted based on the depth of each entry’s transform in the camera’s coordinate space. The implementation of this function will be presented later.
	\item \texttt{InitialClearCmdBuffer}: This function initializes and clears a command buffer, \texttt{m\textunderscore CommandBuffer}, before attaching it to the camera. By doing so, draw commands, which are created in later parts of the code, can be enqueued into this buffer. Each draw command ensures execution during the later rendering process if it is not culled.
	\item The function creates a temporary render target, \texttt{GaussianSplatRT}, sets it as the active render target, and clears it. Consequently, any draw calls issued before the render target is switched again will render to this temporary target rather than directly to the camera’s output.
	\item \texttt{SortAndRenderSplats}: This function is responsible for the main calculations. It processes all collected splats and enqueues the necessary draw commands to render them into \texttt{GaussianSplatRT}. The implementation of this function will be presented later.
	\item  The render target is reset to the camera’s primary output, after which a \texttt{DrawProcedural} call is issued using a designated material. This material is associated with a shader that generates a single triangle that covers the entire screen in its vertex shader. The fragment shader subsequently reads data from \texttt{GaussianSplatRT} and applies gamma correction. This \texttt{DrawProcedural} call enqueues the rendering of this full-screen triangle, ensuring that the Gaussian Splats are correctly displayed in the final rendered image.
\end{itemize}
To fully understand what gets rendered to the screen, it is essential to take a close look at \texttt{SortAndRenderSplats}:
\begin{lstlisting}[tabsize=2,caption=\texttt{SortAndRenderSplats} of \texttt{GaussianSplatRenderSystem}, label=code:systemsortrender,breaklines=true,breakatwhitespace=true,basicstyle=\ttfamily\footnotesize]
public Material SortAndRenderSplats(Camera cam, CommandBuffer cmb)
{
	Material matComposite = null;
	foreach (var kvp in m_ActiveSplats)
	{
		var gs = kvp.Item1;
		matComposite = gs.m_MatComposite;
		var mpb = kvp.Item2;
		
		// sort
		var matrix = gs.transform.localToWorldMatrix;
		if (gs.m_FrameCounter % gs.m_SortNthFrame == 0)
		gs.SortPoints(cmb, cam, matrix);
		++gs.m_FrameCounter;
		
		kvp.Item2.Clear();
		
		// [Omitted: Set some variables related to debugging]
		
		gs.SetAssetDataOnMaterial(mpb);
		mpb.SetBuffer(GaussianSplatRenderer.Props.SplatChunks, gs.m_GpuChunks);
		
		mpb.SetBuffer(GaussianSplatRenderer.Props.SplatViewData, gs.m_GpuView);
		
		mpb.SetBuffer(GaussianSplatRenderer.Props.OrderBuffer, gs.m_GpuSortKeys);
		mpb.SetFloat(GaussianSplatRenderer.Props.SplatScale, gs.m_SplatScale);
		mpb.SetFloat(GaussianSplatRenderer.Props.SplatOpacityScale, gs.m_OpacityScale);
		mpb.SetFloat(GaussianSplatRenderer.Props.SplatSize, gs.m_PointDisplaySize);
		mpb.SetInteger(GaussianSplatRenderer.Props.SHOrder, gs.m_SHOrder);
		mpb.SetInteger(GaussianSplatRenderer.Props.SHOnly, gs.m_SHOnly ? 1 : 0);
		mpb.SetInteger(GaussianSplatRenderer.Props.DisplayIndex, gs.m_RenderMode == GaussianSplatRenderer.RenderMode.DebugPointIndices ? 1 : 0);
		mpb.SetInteger(GaussianSplatRenderer.Props.DisplayChunks, gs.m_RenderMode == GaussianSplatRenderer.RenderMode.DebugChunkBounds ? 1 : 0);
		
		cmb.BeginSample(s_ProfCalcView);
		gs.CalcViewData(cmb, cam, matrix);
		cmb.EndSample(s_ProfCalcView);
		
		// [Omitted: Set some variables related to debugging]
		
		cmb.BeginSample(s_ProfDraw);
		cmb.DrawProcedural(gs.m_GpuIndexBuffer, matrix, displayMat, 0, topology, indexCount, instanceCount, mpb);
		cmb.EndSample(s_ProfDraw);
	}
	return matComposite;
}
\end{lstlisting}
This code block is extensive and encompasses multiple operations. To facilitate a clearer understanding, it will be analyzed step by step, broken down into its fundamental components. Additionally, certain sections of the code are dedicated to debugging or timing purposes, which are not essential for understanding the main rendering pipeline.\\\\
The function iterates over all \texttt{GaussianSplatRenderer} objects stored and ordered in the \texttt{m\textunderscore ActiveSplats} list by \texttt{GatherSplatsForCamera}. It is important to emphasize that within this function, all subsequent operations are performed on a single \texttt{GaussianSplatRenderer} object at a time, as each iteration of the loop processes one individual \texttt{GaussianSplatRenderer}.\\\\
At regular intervals, specifically every set number of frames, the splats undergo sorting. This operation is managed by a custom sorter class, which was initialized during the \texttt{OnEnable} method. The class implements a specialized sorting algorithm known as "Device Radix Sort," leveraging the full potential of the GPU to ensure optimal performance. According to the comments in that class, this algorithm was adapted from another GitHub project \parencite{Sorting}. As with the sorting of the \texttt{GaussianSplatRenderer} objects, the depth of each splat relative to the camera’s coordinate space is used as the key for sorting.
\\\\
Similar to the final \texttt{DrawProcedural} invocation of the previous function, a material shader is employed at the end of each iteration of the loop to render the splats. Many of the operations within this loop are dedicated to populating graphics buffers with the necessary data for these shader computations. The most significant step in this process is the invocation of \texttt{CalcViewData}, which dispatches splat-related information to a compute shader. This compute shader determines the screen-space position of each splat using the object's transform matrix, the \texttt{cam.worldToCameraMatrix}, and the \texttt{cam.projectionMatrix}. Additionally, it calculates its independent horizontal and vertical extents, and derives its color and transparency based on the viewing angle and spherical harmonics. The computed results are then stored in a graphics buffer for subsequent use. \\\\
Finally, \texttt{DrawProcedural} is called, enqueueing the rendering of this data for execution later in the rendering pipeline. As before, this rendering is performed using a material shader, a different one from the material shader used in \texttt{OnPreCullCamera}. Each splat is represented as two triangles, with the vertex shader transforming the computed screen position and stretch extents into appropriate triangle coordinates.
\\\\
As a brief reminder, as stated earlier, this \texttt{DrawProcedural} invocation does not render directly to the camera’s output but instead to the temporary render target \texttt{GaussianSplatRT}. Additionally, due to the sorting performed at the beginning of the loop, splats farther from the camera are rendered before those closer to it, ensuring correct per-object rendering order.\\\\
With these steps described, the overall structure of the rendering pipeline for the Gaussian Splats becomes clear. The coordination between sorting, compute shaders, and material shaders ensures that the splats are accurately positioned, stretched, and rendered according to the camera’s view.
\section{Part 1: Correcting the Rendering Order}    
\subsection{Introduction}   
At the outset of this research, no specific focus or predefined problem statement had been established. The initial objective was exploratory in nature: to experiment with the existing Unity extension and investigate the process of importing and animating a Gaussian Splat within the engine.\\
Throughout this exploratory process, particular attention was given to identifying tasks that were difficult to perform, as well as outputs that appeared incorrect or inconsistent. These observations served as the basis for defining the core focus areas of the thesis.
\subsection{Preparing the scene}
To initiate this phase of the research, it was necessary to select a suitable pre-trained Gaussian splat model. Ideally, the chosen model would consist of multiple visually distinct segments, making it intuitive and practical for experimentation with segmentation and animation. The primary models considered were those released by the authors of the original Gaussian Splatting paper. Among them, the Kitchen scene includes a small LEGO bulldozer—an object that is compact, easily recognizable, and composed of several clearly separable parts. These characteristics made it an ideal candidate for the intended use case.
\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Images/Kitchen.png}
	\caption{The Kitchen scene from the official Gaussian Splatting dataset, featuring a small LEGO bulldozer. This object was selected for its compact structure and clearly defined components, making it well-suited for segmentation and animation experiments.}
	\label{fig:kitchen}
\end{figure}
Obviously, not the entire scene is necessary for these purposes; only the LEGO bulldozer is required. Fortunately, the Unity extension being used includes a tool designed specifically for this type of task: cutouts. Within the GaussianSplatRenderer component of the relevant GameObject in the Unity Editor, a cutout can be added to the Gaussian Splat. This tool creates a cutout GameObject (either a box or an ellipsoid) as a child of the selected object. The cutout can be translated, rotated, and scaled like any other GameObject. Any splats of the selected object outside of the cutout are excluded from rendering. Additionally, there is an invert option that reverses the effect, making only the splats within the cutout invisible. A button allows the Gaussian Splat to be saved as a PLY file, accounting for all cutout modifications. This functionality was used to generate a PLY file and associated asset containing only the bulldozer, omitting the rest of the scene.
\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Images/WholeTruck.png}
	\caption{The LEGO bulldozer extracted from the Kitchen scene using the cutout tool of the Unity extension for Gaussian splatting. This tool isolates the bulldozer by excluding all other parts of the scene.}
	\label{fig:wholetruck}
\end{figure}
\newpage \noindent
The next step towards animating the bulldozer involved segmenting multiple parts of the model into individual GameObjects, each parented to the main bulldozer GameObject. This was achieved using the same method as before. As a result, the two rear wheels and the bulldozer's arm were isolated as separate GameObjects, with the arm further subdivided into a subsegment for the bucket. These parts provided a sufficient basis for testing basic animations.\\
However, before even considering animating the subsegments, a significant issue became apparent: there was a clear problem with the rendering of these segments.
\subsection{Initial Workarounds and Approximate Solutions}
\subsection{Towards a Correct Rendering Pipeline}
\section{Part 2: Hierarchical Segmentation}         
\addcontentsline{toc}{section}{References}
\printbibliography
\end{document}
